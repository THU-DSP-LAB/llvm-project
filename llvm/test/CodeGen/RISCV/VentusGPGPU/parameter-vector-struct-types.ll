; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv32 -mcpu=ventus-gpgpu -verify-machineinstrs < %s \
; RUN:   | FileCheck %s

%struct.MyStruct = type { i32, i8, i64 }

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: write) vscale_range(1,2048)
; Here we foucus on kernel struct argument
define dso_local ventus_kernel void @test_kernel1(i8 noundef %c, %struct.MyStruct %st.coerce, i8 noundef %uc, ptr addrspace(1) nocapture noundef writeonly align 4 %result) {
; CHECK-LABEL: test_kernel1:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lb t0, 0(a0)
; CHECK-NEXT:    lbu t1, 24(a0)
; CHECK-NEXT:    lw t2, 28(a0)
; CHECK-NEXT:    fcvt.s.w t0, t0
; CHECK-NEXT:    lw s1, 8(a0)
; CHECK-NEXT:    sw t0, 0(t2)
; CHECK-NEXT:    fcvt.s.w t0, s1
; CHECK-NEXT:    fcvt.s.wu t1, t1
; CHECK-NEXT:    sw t0, 4(t2)
; CHECK-NEXT:    sw t1, 8(t2)
; CHECK-NEXT:    ret
entry:
  %st.coerce.fca.0.extract = extractvalue %struct.MyStruct %st.coerce, 0
  %conv = sitofp i8 %c to float
  store float %conv, ptr addrspace(1) %result, align 4
  %conv1 = sitofp i32 %st.coerce.fca.0.extract to float
  %arrayidx2 = getelementptr inbounds float, ptr addrspace(1) %result, i32 1
  store float %conv1, ptr addrspace(1) %arrayidx2, align 4
  %conv3 = uitofp i8 %uc to float
  %arrayidx4 = getelementptr inbounds float, ptr addrspace(1) %result, i32 2
  store float %conv3, ptr addrspace(1) %arrayidx4, align 4
  ret void
}

; Function Attrs: mustprogress nofree norecurse nosync nounwind willreturn memory(argmem: write) vscale_range(1,2048)
; Here we foucus on scalar argument
define dso_local ventus_kernel void @test_kernel2(i8 noundef %c, i8 noundef %uc, i16 noundef %s, i16 noundef %us, i32 noundef %i, i32 noundef %ui, float noundef %f, ptr addrspace(1) nocapture noundef writeonly align 4 %result) {
; CHECK-LABEL: test_kernel2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lw t0, 24(a0)
; CHECK-NEXT:    lw t1, 20(a0)
; CHECK-NEXT:    lw t2, 16(a0)
; CHECK-NEXT:    lhu s1, 12(a0)
; CHECK-NEXT:    lh a1, 8(a0)
; CHECK-NEXT:    lb a2, 0(a0)
; CHECK-NEXT:    lbu a3, 4(a0)
; CHECK-NEXT:    lw a0, 28(a0)
; CHECK-NEXT:    fcvt.s.w a2, a2
; CHECK-NEXT:    fcvt.s.wu a3, a3
; CHECK-NEXT:    sw a2, 0(a0)
; CHECK-NEXT:    sw a3, 4(a0)
; CHECK-NEXT:    fcvt.s.w a1, a1
; CHECK-NEXT:    fcvt.s.wu s1, s1
; CHECK-NEXT:    sw a1, 8(a0)
; CHECK-NEXT:    sw s1, 12(a0)
; CHECK-NEXT:    fcvt.s.w t2, t2
; CHECK-NEXT:    fcvt.s.wu t1, t1
; CHECK-NEXT:    sw t2, 16(a0)
; CHECK-NEXT:    sw t1, 20(a0)
; CHECK-NEXT:    sw t0, 24(a0)
; CHECK-NEXT:    ret
entry:
  %conv = sitofp i8 %c to float
  store float %conv, ptr addrspace(1) %result, align 4
  %conv1 = uitofp i8 %uc to float
  %arrayidx2 = getelementptr inbounds float, ptr addrspace(1) %result, i32 1
  store float %conv1, ptr addrspace(1) %arrayidx2, align 4
  %conv3 = sitofp i16 %s to float
  %arrayidx4 = getelementptr inbounds float, ptr addrspace(1) %result, i32 2
  store float %conv3, ptr addrspace(1) %arrayidx4, align 4
  %conv5 = uitofp i16 %us to float
  %arrayidx6 = getelementptr inbounds float, ptr addrspace(1) %result, i32 3
  store float %conv5, ptr addrspace(1) %arrayidx6, align 4
  %conv7 = sitofp i32 %i to float
  %arrayidx8 = getelementptr inbounds float, ptr addrspace(1) %result, i32 4
  store float %conv7, ptr addrspace(1) %arrayidx8, align 4
  %conv9 = uitofp i32 %ui to float
  %arrayidx10 = getelementptr inbounds float, ptr addrspace(1) %result, i32 5
  store float %conv9, ptr addrspace(1) %arrayidx10, align 4
  %arrayidx11 = getelementptr inbounds float, ptr addrspace(1) %result, i32 6
  store float %f, ptr addrspace(1) %arrayidx11, align 4
  ret void
}

; Function Attrs: convergent mustprogress nofree norecurse nounwind willreturn memory(argmem: write) vscale_range(1,2048)
; Here we foucus on vector argument
define dso_local ventus_kernel void @test_kernel3(<2 x i8> noundef %c, <2 x i8> noundef %uc, <2 x i16> noundef %s, <2 x i16> noundef %us, <2 x i32> noundef %i, <2 x i32> noundef %ui, <2 x float> noundef %f, ptr addrspace(1) nocapture noundef writeonly align 8 %result) {
; CHECK-LABEL: test_kernel3:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, 56
; CHECK-NEXT:    .cfi_def_cfa_offset 56
; CHECK-NEXT:    addi tp, tp, 4
; CHECK-NEXT:    .cfi_def_cfa_offset 4
; CHECK-NEXT:    regext zero, zero, 1
; CHECK-NEXT:    vmv.v.x v32, tp
; CHECK-NEXT:    sw ra, -56(sp) # 4-byte Folded Spill
; CHECK-NEXT:    regext zero, zero, 72
; CHECK-NEXT:    vsw.v v33, -4(v32) # 4-byte Folded Spill
; CHECK-NEXT:    .cfi_offset ra, 0
; CHECK-NEXT:    .cfi_offset v33.l, 0
; CHECK-NEXT:    lw t0, 36(a0)
; CHECK-NEXT:    sw t0, -4(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 32(a0)
; CHECK-NEXT:    sw t0, -8(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 28(a0)
; CHECK-NEXT:    sw t0, -12(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 24(a0)
; CHECK-NEXT:    sw t0, -16(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 20(a0)
; CHECK-NEXT:    sw t0, -20(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 16(a0)
; CHECK-NEXT:    sw t0, -24(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 14(a0)
; CHECK-NEXT:    sw t0, -28(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 12(a0)
; CHECK-NEXT:    sw t0, -32(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 10(a0)
; CHECK-NEXT:    sw t0, -36(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 8(a0)
; CHECK-NEXT:    sw t0, -40(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lbu t0, 5(a0)
; CHECK-NEXT:    sw t0, -44(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lbu t0, 4(a0)
; CHECK-NEXT:    sw t0, -48(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lbu t0, 1(a0)
; CHECK-NEXT:    lbu t1, 0(a0)
; CHECK-NEXT:    lw t2, 40(a0)
; CHECK-NEXT:    sw t2, -52(sp) # 4-byte Folded Spill
; CHECK-NEXT:    vmv.v.x v0, t1
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_c
; CHECK-NEXT:    lw t0, -52(sp) # 4-byte Folded Reload
; CHECK-NEXT:    regext zero, zero, 1
; CHECK-NEXT:    vmv.v.x v33, t0
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 4(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 0(v33)
; CHECK-NEXT:    lw t0, -48(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -44(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_h
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 12(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 8(v33)
; CHECK-NEXT:    lw t0, -40(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -36(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_s
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 20(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 16(v33)
; CHECK-NEXT:    lw t0, -32(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -28(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_t
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 28(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 24(v33)
; CHECK-NEXT:    lw t0, -24(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -20(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_i
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 36(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 32(v33)
; CHECK-NEXT:    lw t0, -16(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -12(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_j
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 44(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 40(v33)
; CHECK-NEXT:    lw t0, -8(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -4(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    call _Z14convert_float2Dv2_f
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 52(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 48(v33)
; CHECK-NEXT:    lw ra, -56(sp) # 4-byte Folded Reload
; CHECK-NEXT:    regext zero, zero, 9
; CHECK-NEXT:    vlw.v v33, -4(v32) # 4-byte Folded Reload
; CHECK-NEXT:    addi sp, sp, -56
; CHECK-NEXT:    addi tp, tp, -4
; CHECK-NEXT:    regext zero, zero, 1
; CHECK-NEXT:    vmv.v.x v32, tp
; CHECK-NEXT:    ret
entry:
  %call = call <2 x float> @_Z14convert_float2Dv2_c(<2 x i8> noundef %c)
  store <2 x float> %call, ptr addrspace(1) %result, align 8
  %call1 = call <2 x float> @_Z14convert_float2Dv2_h(<2 x i8> noundef %uc)
  %arrayidx2 = getelementptr inbounds <2 x float>, ptr addrspace(1) %result, i32 1
  store <2 x float> %call1, ptr addrspace(1) %arrayidx2, align 8
  %call3 = call <2 x float> @_Z14convert_float2Dv2_s(<2 x i16> noundef %s)
  %arrayidx4 = getelementptr inbounds <2 x float>, ptr addrspace(1) %result, i32 2
  store <2 x float> %call3, ptr addrspace(1) %arrayidx4, align 8
  %call5 = call <2 x float> @_Z14convert_float2Dv2_t(<2 x i16> noundef %us)
  %arrayidx6 = getelementptr inbounds <2 x float>, ptr addrspace(1) %result, i32 3
  store <2 x float> %call5, ptr addrspace(1) %arrayidx6, align 8
  %call7 = call <2 x float> @_Z14convert_float2Dv2_i(<2 x i32> noundef %i)
  %arrayidx8 = getelementptr inbounds <2 x float>, ptr addrspace(1) %result, i32 4
  store <2 x float> %call7, ptr addrspace(1) %arrayidx8, align 8
  %call9 = call <2 x float> @_Z14convert_float2Dv2_j(<2 x i32> noundef %ui)
  %arrayidx10 = getelementptr inbounds <2 x float>, ptr addrspace(1) %result, i32 5
  store <2 x float> %call9, ptr addrspace(1) %arrayidx10, align 8
  %call11 = call <2 x float> @_Z14convert_float2Dv2_f(<2 x float> noundef %f)
  %arrayidx12 = getelementptr inbounds <2 x float>, ptr addrspace(1) %result, i32 6
  store <2 x float> %call11, ptr addrspace(1) %arrayidx12, align 8
  ret void
}

declare dso_local <2 x float> @_Z14convert_float2Dv2_c(<2 x i8> noundef)
declare dso_local <2 x float> @_Z14convert_float2Dv2_h(<2 x i8> noundef)
declare dso_local <2 x float> @_Z14convert_float2Dv2_s(<2 x i16> noundef)
declare dso_local <2 x float> @_Z14convert_float2Dv2_t(<2 x i16> noundef)
declare dso_local <2 x float> @_Z14convert_float2Dv2_i(<2 x i32> noundef)
declare dso_local <2 x float> @_Z14convert_float2Dv2_j(<2 x i32> noundef)
declare dso_local <2 x float> @_Z14convert_float2Dv2_f(<2 x float> noundef)

; Function Attrs: convergent mustprogress nofree norecurse nounwind willreturn memory(argmem: write) vscale_range(1,2048)
; Here we foucus on vector argument
define dso_local ventus_kernel void @test_kernel4(<4 x i8> noundef %c, <4 x i8> noundef %uc, <4 x i16> noundef %s, <4 x i16> noundef %us, <4 x i32> noundef %i, <4 x i32> noundef %ui, <4 x float> noundef %f, ptr addrspace(1) nocapture noundef writeonly align 16 %result) {
; CHECK-LABEL: test_kernel4:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    addi sp, sp, 104
; CHECK-NEXT:    .cfi_def_cfa_offset 104
; CHECK-NEXT:    addi tp, tp, 4
; CHECK-NEXT:    .cfi_def_cfa_offset 4
; CHECK-NEXT:    regext zero, zero, 1
; CHECK-NEXT:    vmv.v.x v32, tp
; CHECK-NEXT:    sw ra, -104(sp) # 4-byte Folded Spill
; CHECK-NEXT:    regext zero, zero, 72
; CHECK-NEXT:    vsw.v v33, -4(v32) # 4-byte Folded Spill
; CHECK-NEXT:    .cfi_offset ra, 0
; CHECK-NEXT:    .cfi_offset v33.l, 0
; CHECK-NEXT:    lw t0, 76(a0)
; CHECK-NEXT:    sw t0, -4(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 72(a0)
; CHECK-NEXT:    sw t0, -8(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 68(a0)
; CHECK-NEXT:    sw t0, -12(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 64(a0)
; CHECK-NEXT:    sw t0, -16(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 60(a0)
; CHECK-NEXT:    sw t0, -20(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 56(a0)
; CHECK-NEXT:    sw t0, -24(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 52(a0)
; CHECK-NEXT:    sw t0, -28(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 48(a0)
; CHECK-NEXT:    sw t0, -32(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 44(a0)
; CHECK-NEXT:    sw t0, -36(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 40(a0)
; CHECK-NEXT:    sw t0, -40(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 36(a0)
; CHECK-NEXT:    sw t0, -44(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 32(a0)
; CHECK-NEXT:    sw t0, -48(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 22(a0)
; CHECK-NEXT:    sw t0, -52(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 20(a0)
; CHECK-NEXT:    sw t0, -56(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 18(a0)
; CHECK-NEXT:    sw t0, -60(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 16(a0)
; CHECK-NEXT:    sw t0, -64(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 14(a0)
; CHECK-NEXT:    sw t0, -68(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 12(a0)
; CHECK-NEXT:    sw t0, -72(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 10(a0)
; CHECK-NEXT:    sw t0, -76(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lhu t0, 8(a0)
; CHECK-NEXT:    sw t0, -80(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 4(a0)
; CHECK-NEXT:    lbu t1, 4(a0)
; CHECK-NEXT:    sw t1, -88(sp) # 4-byte Folded Spill
; CHECK-NEXT:    srli t1, t0, 24
; CHECK-NEXT:    sw t1, -84(sp) # 4-byte Folded Spill
; CHECK-NEXT:    srli t1, t0, 8
; CHECK-NEXT:    andi t1, t1, 255
; CHECK-NEXT:    sw t1, -92(sp) # 4-byte Folded Spill
; CHECK-NEXT:    srli t0, t0, 16
; CHECK-NEXT:    andi t0, t0, 255
; CHECK-NEXT:    sw t0, -96(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 80(a0)
; CHECK-NEXT:    sw t0, -100(sp) # 4-byte Folded Spill
; CHECK-NEXT:    lw t0, 0(a0)
; CHECK-NEXT:    lbu t1, 0(a0)
; CHECK-NEXT:    srli t2, t0, 24
; CHECK-NEXT:    srli s1, t0, 8
; CHECK-NEXT:    andi s1, s1, 255
; CHECK-NEXT:    srli t0, t0, 16
; CHECK-NEXT:    andi t0, t0, 255
; CHECK-NEXT:    vmv.v.x v0, t1
; CHECK-NEXT:    vmv.v.x v1, s1
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    vmv.v.x v3, t2
; CHECK-NEXT:    call _Z14convert_float4Dv4_c
; CHECK-NEXT:    lw t0, -100(sp) # 4-byte Folded Reload
; CHECK-NEXT:    regext zero, zero, 1
; CHECK-NEXT:    vmv.v.x v33, t0
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 12(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 8(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 4(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 0(v33)
; CHECK-NEXT:    lw t0, -88(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -92(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    lw t0, -96(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    lw t0, -84(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v3, t0
; CHECK-NEXT:    call _Z14convert_float4Dv4_h
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 28(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 24(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 20(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 16(v33)
; CHECK-NEXT:    lw t0, -80(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -76(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    lw t0, -72(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    lw t0, -68(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v3, t0
; CHECK-NEXT:    call _Z14convert_float4Dv4_s
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 44(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 40(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 36(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 32(v33)
; CHECK-NEXT:    lw t0, -64(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -60(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    lw t0, -56(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    lw t0, -52(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v3, t0
; CHECK-NEXT:    call _Z14convert_float4Dv4_t
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 60(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 56(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 52(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 48(v33)
; CHECK-NEXT:    lw t0, -48(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -44(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    lw t0, -40(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    lw t0, -36(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v3, t0
; CHECK-NEXT:    call _Z14convert_float4Dv4_i
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 76(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 72(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 68(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 64(v33)
; CHECK-NEXT:    lw t0, -32(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -28(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    lw t0, -24(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    lw t0, -20(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v3, t0
; CHECK-NEXT:    call _Z14convert_float4Dv4_j
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 92(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 88(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 84(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 80(v33)
; CHECK-NEXT:    lw t0, -16(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v0, t0
; CHECK-NEXT:    lw t0, -12(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v1, t0
; CHECK-NEXT:    lw t0, -8(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v2, t0
; CHECK-NEXT:    lw t0, -4(sp) # 4-byte Folded Reload
; CHECK-NEXT:    vmv.v.x v3, t0
; CHECK-NEXT:    call _Z14convert_float4Dv4_f
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v3, 108(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v2, 104(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v1, 100(v33)
; CHECK-NEXT:    regext zero, zero, 8
; CHECK-NEXT:    vsw12.v v0, 96(v33)
; CHECK-NEXT:    lw ra, -104(sp) # 4-byte Folded Reload
; CHECK-NEXT:    regext zero, zero, 9
; CHECK-NEXT:    vlw.v v33, -4(v32) # 4-byte Folded Reload
; CHECK-NEXT:    addi sp, sp, -104
; CHECK-NEXT:    addi tp, tp, -4
; CHECK-NEXT:    regext zero, zero, 1
; CHECK-NEXT:    vmv.v.x v32, tp
; CHECK-NEXT:    ret
entry:
  %call = call <4 x float> @_Z14convert_float4Dv4_c(<4 x i8> noundef %c)
  store <4 x float> %call, ptr addrspace(1) %result, align 16
  %call1 = call <4 x float> @_Z14convert_float4Dv4_h(<4 x i8> noundef %uc)
  %arrayidx2 = getelementptr inbounds <4 x float>, ptr addrspace(1) %result, i32 1
  store <4 x float> %call1, ptr addrspace(1) %arrayidx2, align 16
  %call3 = call <4 x float> @_Z14convert_float4Dv4_s(<4 x i16> noundef %s)
  %arrayidx4 = getelementptr inbounds <4 x float>, ptr addrspace(1) %result, i32 2
  store <4 x float> %call3, ptr addrspace(1) %arrayidx4, align 16
  %call5 = call <4 x float> @_Z14convert_float4Dv4_t(<4 x i16> noundef %us)
  %arrayidx6 = getelementptr inbounds <4 x float>, ptr addrspace(1) %result, i32 3
  store <4 x float> %call5, ptr addrspace(1) %arrayidx6, align 16
  %call7 = call <4 x float> @_Z14convert_float4Dv4_i(<4 x i32> noundef %i)
  %arrayidx8 = getelementptr inbounds <4 x float>, ptr addrspace(1) %result, i32 4
  store <4 x float> %call7, ptr addrspace(1) %arrayidx8, align 16
  %call9 = call <4 x float> @_Z14convert_float4Dv4_j(<4 x i32> noundef %ui)
  %arrayidx10 = getelementptr inbounds <4 x float>, ptr addrspace(1) %result, i32 5
  store <4 x float> %call9, ptr addrspace(1) %arrayidx10, align 16
  %call11 = call <4 x float> @_Z14convert_float4Dv4_f(<4 x float> noundef %f)
  %arrayidx12 = getelementptr inbounds <4 x float>, ptr addrspace(1) %result, i32 6
  store <4 x float> %call11, ptr addrspace(1) %arrayidx12, align 16
  ret void
}

declare dso_local <4 x float> @_Z14convert_float4Dv4_c(<4 x i8> noundef)
declare dso_local <4 x float> @_Z14convert_float4Dv4_h(<4 x i8> noundef)
declare dso_local <4 x float> @_Z14convert_float4Dv4_s(<4 x i16> noundef)
declare dso_local <4 x float> @_Z14convert_float4Dv4_t(<4 x i16> noundef)
declare dso_local <4 x float> @_Z14convert_float4Dv4_i(<4 x i32> noundef)
declare dso_local <4 x float> @_Z14convert_float4Dv4_j(<4 x i32> noundef)
declare dso_local <4 x float> @_Z14convert_float4Dv4_f(<4 x float> noundef)
